{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T03:15:11.070207098Z",
     "start_time": "2023-07-11T03:15:11.020365468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import json\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "cwd = \"/Users/jonathanlin/Documents/GitHub/research_transfer/datasets/Animal_Kingdom/pose_estimation/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T03:15:19.954417343Z",
     "start_time": "2023-07-11T03:15:19.948435517Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ak_dataset(Dataset):\n",
    "    \"\"\"dataset for Animal Kingdom\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, animal_label, transform=None):\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_to_int = {}\n",
    "        if animal_label == \"animal_parent_class\":\n",
    "            self.label_to_int = {\n",
    "                \"Reptile\": 0,\n",
    "                \"Bird\": 1,\n",
    "                \"Mammal\": 2,\n",
    "                \"Amphibian\": 3,\n",
    "                \"Fish\": 4\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # this dictionary converts the string labels to integers\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        \n",
    "        label = self.label_to_int[self.landmarks_frame.iloc[idx, 1]]\n",
    "\n",
    "        image = io.imread(img_name)\n",
    "        if image.shape != torch.Size([360, 640, 3]):\n",
    "            print(self.landmarks_frame.iloc[idx, 0])\n",
    "\n",
    "        image = np.reshape(image, (3, 360, 640))\n",
    "        image = (torch.from_numpy(image)).to(torch.float32)\n",
    "\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RXRDIUMD/RXRDIUMD_f000042.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 676080 into shape (3,360,640)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset)):\n\u001b[1;32m      8\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mlen\u001b[39m(dataset))\n\u001b[0;32m----> 9\u001b[0m     sample \u001b[39m=\u001b[39m dataset[idx]\n\u001b[1;32m     10\u001b[0m     sizes\u001b[39m.\u001b[39madd((sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)))\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(sizes)\n",
      "Cell \u001b[0;32mIn[23], line 37\u001b[0m, in \u001b[0;36mak_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mSize([\u001b[39m360\u001b[39m, \u001b[39m640\u001b[39m, \u001b[39m3\u001b[39m]):\n\u001b[1;32m     35\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlandmarks_frame\u001b[39m.\u001b[39miloc[idx, \u001b[39m0\u001b[39m])\n\u001b[0;32m---> 37\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(image, (\u001b[39m3\u001b[39;49m, \u001b[39m360\u001b[39;49m, \u001b[39m640\u001b[39;49m))\n\u001b[1;32m     38\u001b[0m image \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mfrom_numpy(image))\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     40\u001b[0m \u001b[39mreturn\u001b[39;00m (image, label)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 676080 into shape (3,360,640)"
     ]
    }
   ],
   "source": [
    "dataset = ak_dataset(csv_file= \"ak_classification_data_test.csv\",\n",
    "                    root_dir= cwd,\n",
    "                    animal_label = \"animal_parent_class\")\n",
    "\n",
    "sizes = set()\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    sample = dataset[idx]\n",
    "    sizes.add((sample[0].size(dim=0), sample[0].size(dim=1), sample[0].size(dim=2)))\n",
    "\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T03:16:13.043370919Z",
     "start_time": "2023-07-11T03:16:12.421598661Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 676080 into shape (3,360,640)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset)):\n\u001b[1;32m      8\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mlen\u001b[39m(dataset))\n\u001b[0;32m----> 9\u001b[0m     sample \u001b[39m=\u001b[39m dataset[idx]\n\u001b[1;32m     10\u001b[0m     sizes\u001b[39m.\u001b[39madd((sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), sample[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msize(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)))\n\u001b[1;32m     11\u001b[0m     \u001b[39m# if sample[0].shape != torch.Size([3, 360, 640]):\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39m#     print(sample[0].shape)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39m#     break\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m, in \u001b[0;36mak_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_to_int[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlandmarks_frame\u001b[39m.\u001b[39miloc[idx, \u001b[39m1\u001b[39m]]\n\u001b[1;32m     33\u001b[0m image \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mimread(img_name)\n\u001b[0;32m---> 34\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(image, (\u001b[39m3\u001b[39;49m, \u001b[39m360\u001b[39;49m, \u001b[39m640\u001b[39;49m))\n\u001b[1;32m     35\u001b[0m image \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mfrom_numpy(image))\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m (image, label)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 676080 into shape (3,360,640)"
     ]
    }
   ],
   "source": [
    "dataset = ak_dataset(csv_file= \"ak_classification_data_test.csv\",\n",
    "                    root_dir= cwd,\n",
    "                    animal_label = \"animal_parent_class\")\n",
    "\n",
    "sizes = set()\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    sample = dataset[idx]\n",
    "    sizes.add((sample[0].size(dim=0), sample[0].size(dim=1), sample[0].size(dim=2)))\n",
    "    # if sample[0].shape != torch.Size([3, 360, 640]):\n",
    "    #     print(sample[0].shape)\n",
    "    #     break\n",
    "\n",
    "print(sizes)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "# for i in range(len(dataset)):\n",
    "#     idx = np.random.randint(len(dataset))\n",
    "#     sample = dataset[idx]\n",
    "\n",
    "#     ax = plt.subplot(1, 5, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     ax.axis('off')\n",
    "\n",
    "#     image = np.reshape(sample[0], (360, 640, 3))\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(sample[1])\n",
    "\n",
    "#     if i == 4:\n",
    "#         plt.show()\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
