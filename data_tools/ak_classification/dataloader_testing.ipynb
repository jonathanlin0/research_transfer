{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T03:15:11.070207098Z",
     "start_time": "2023-07-11T03:15:11.020365468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import json\n",
    "import torchvision\n",
    "import PIL\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "cwd = \"/Users/jonathanlin/Documents/GitHub/research_transfer/datasets/Animal_Kingdom/pose_estimation/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T03:15:19.954417343Z",
     "start_time": "2023-07-11T03:15:19.948435517Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ak_dataset(Dataset):\n",
    "    \"\"\"dataset for Animal Kingdom\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, animal_label, transform=None):\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_to_int = {}\n",
    "        if animal_label == \"animal_parent_class\":\n",
    "            self.label_to_int = {\n",
    "                \"Reptile\": 0,\n",
    "                \"Bird\": 1,\n",
    "                \"Mammal\": 2,\n",
    "                \"Amphibian\": 3,\n",
    "                \"Fish\": 4\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # this dictionary converts the string labels to integers\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        \n",
    "        label = self.label_to_int[self.landmarks_frame.iloc[idx, 1]]\n",
    "\n",
    "        image = PIL.Image.open(img_name, mode=\"r\")\n",
    "        # image = io.imread(img_name)\n",
    "        \n",
    "        print(type(image))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = np.reshape(image, (3, 360, 640))\n",
    "        image = image.to(torch.float32)\n",
    "\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-11T03:16:13.043370919Z",
     "start_time": "2023-07-11T03:16:12.421598661Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[1;32m     14\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39mlen\u001b[39m(dataset))\n\u001b[0;32m---> 15\u001b[0m     sample \u001b[39m=\u001b[39m dataset[idx]\n\u001b[1;32m     17\u001b[0m     ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m, num_samples, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n",
      "Cell \u001b[0;32mIn[138], line 31\u001b[0m, in \u001b[0;36mak_dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     28\u001b[0m img_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir,\n\u001b[1;32m     29\u001b[0m                         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlandmarks_frame\u001b[39m.\u001b[39miloc[idx, \u001b[39m0\u001b[39m])\n\u001b[0;32m---> 31\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_to_int[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlandmarks_frame\u001b[39m.\u001b[39;49miloc[idx, \u001b[39m1\u001b[39;49m]]\n\u001b[1;32m     33\u001b[0m image \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mopen(img_name, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39m# image = io.imread(img_name)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = ak_dataset(csv_file=\"dataset_test.csv\",\n",
    "                     root_dir=cwd,\n",
    "                     animal_label=\"animal_parent_class\",\n",
    "                     transform=torchvision.transforms.Compose([\n",
    "                         transforms.RandomHorizontalFlip(),\n",
    "                         transforms.RandAugment(),\n",
    "                         transforms.ToTensor()\n",
    "                     ]))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "num_samples = 5\n",
    "\n",
    "for i in range(num_samples):\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    sample = dataset[idx]\n",
    "\n",
    "    ax = plt.subplot(1, num_samples, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "\n",
    "    image = sample[0].cpu().numpy()\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "    plt.imshow(image, vmin=0, vmax=1)\n",
    "    plt.title(sample[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
